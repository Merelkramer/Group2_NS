{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58426e1f",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "74af7a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DAGDEELTREIN',\n",
       " 'train_type',\n",
       " 'PROGNOSE_REIZEN',\n",
       " 'Rain_flag',\n",
       " 'Heavy_Rain_flag',\n",
       " 'Gusts_flag',\n",
       " 'Storms_flag',\n",
       " 'Warm_flag',\n",
       " 'Cold_flag',\n",
       " 'Sunny_flag',\n",
       " 'Cancelled',\n",
       " 'ExtraTrain',\n",
       " 'delay_category',\n",
       " 'disruption_category',\n",
       " 'Previous train canceled',\n",
       " 'Previous train delayed',\n",
       " 'disrupt_any']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 1) Setup ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# --- 2) Load data ---\n",
    "df = pd.read_csv(\n",
    "    \"/Users/amelijaancupane/Desktop/TU_DELFT/Year 2/Advanced Data Analysis/NS_Project/Group2_NS-1/data/complete_dataset_clean_vf.csv\",\n",
    "    sep=\";\"\n",
    ")\n",
    "\n",
    "# --- 3) Data cleaning---\n",
    "\n",
    "# drop rows with missing target\n",
    "df = df.dropna(subset=[\"REALISATIE\"]).reset_index(drop=True)\n",
    "df[\"REALISATIE\"] = df[\"REALISATIE\"].astype(float)\n",
    "\n",
    "\n",
    "# booleans to ints (safer for sklearn)\n",
    "for col in [\"Cancelled\", \"ExtraTrain\", \"Previous train canceled\", \"Previous train delayed\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype(int)\n",
    "\n",
    "\n",
    "# --- 4) Target and features ---\n",
    "y = df[\"REALISATIE\"]\n",
    "\n",
    "base_features = [\"DAGDEELTREIN\", \"train_type\", \"PROGNOSE_REIZEN\"]\n",
    "\n",
    "weather_features = [c for c in [\n",
    "    \"Rain_flag\",\"Heavy_Rain_flag\",\"Gusts_flag\",\"Storms_flag\",\"Warm_flag\",\"Cold_flag\",\"Sunny_flag\"\n",
    "] if c in df.columns]\n",
    "\n",
    "disrupt_features = [c for c in [\n",
    "    \"Cancelled\",\"ExtraTrain\",\"delay_category\",\"disruption_category\",\n",
    "    \"Previous train canceled\",\"Previous train delayed\", \"disrupt_any\"\n",
    "] if c in df.columns]\n",
    "\n",
    "\n",
    "features_all = [c for c in (base_features + weather_features + disrupt_features) if c in df.columns]\n",
    "\n",
    "features_all\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df3c791",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "24ffb182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total model features (post one-hot): 26\n",
      "Train: (75158, 26) | Test: (23459, 26)\n",
      "\n",
      "Linear Regression — Test results (full feature set):\n",
      "MAE: 63.21\n",
      "RMSE: 92.14\n",
      "R²: 0.817\n",
      "\n",
      "Operator Forecast (PROGNOSE_REIZEN) — Test results:\n",
      "MAE: 61.69\n",
      "RMSE: 99.62\n",
      "R²: 0.786\n",
      "\n",
      "=== Comparison of feature sets (Linear Regression) ===\n",
      "                               Feature Set  MAE (Model)  RMSE (Model)  R² (Model)  MAE (Disrupted)  RMSE (Disrupted)  R² (Disrupted)  n_features\n",
      "0           Set 4: Base + Disruptions full        59.21         91.04       0.821            67.84            104.50           0.801          19\n",
      "1  Set 5: Base + Delay and Disruption cats        59.45         92.93       0.814            69.05            108.22           0.786          14\n",
      "2                 Set 1: Base + Delay cats        59.50         92.99       0.814            69.19            108.35           0.786          11\n",
      "3            Set 2: Base + Disruption cats        59.68         93.59       0.811            69.80            110.83           0.776          10\n",
      "4             Operator Forecast (baseline)        61.69         99.62       0.786            71.26            113.18           0.766           1\n",
      "5                               Set 6: ALL        63.21         92.14       0.817            71.72            105.03           0.799          26\n",
      "6                    Set 3: Base + Weather        63.91         94.48       0.808            71.47            108.97           0.783          14\n",
      "\n",
      "Saved THE model: Set 4: Base + Disruptions full  | Overall Test MAE=59.21  | n_features=19\n"
     ]
    }
   ],
   "source": [
    "X = df[features_all].copy()\n",
    "\n",
    "# one-hot encode categoricals\n",
    "categorical_cols = [c for c in [\"DAGDEELTREIN\", \"train_type\", \"delay_category\", \"disruption_category\"] if c in X.columns]\n",
    "X = pd.get_dummies(X, columns=categorical_cols, drop_first=True)\n",
    "\n",
    "print(f\"Total model features (post one-hot): {X.shape[1]}\")\n",
    "\n",
    "# --- 5) Chronological split: last 7 days as TEST ---\n",
    "cutoff_day = df[\"DAGNR\"].max() - 7\n",
    "train_mask = df[\"DAGNR\"] <= cutoff_day\n",
    "test_mask  = df[\"DAGNR\"] >  cutoff_day\n",
    "\n",
    "X_train = X[train_mask]\n",
    "y_train = y[train_mask]\n",
    "X_test  = X[test_mask]\n",
    "y_test  = y[test_mask]\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"| Test:\", X_test.shape)\n",
    "\n",
    "# --- 6) Train & evaluate Linear Regression on full feature set ---\n",
    "lin_model = LinearRegression()\n",
    "lin_model.fit(X_train, y_train)\n",
    "y_pred = lin_model.predict(X_test)\n",
    "\n",
    "mae  = mean_absolute_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2   = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\nLinear Regression — Test results (full feature set):\")\n",
    "print(f\"MAE: {mae:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R²: {r2:.3f}\")\n",
    "\n",
    "# Operator baseline on the same TEST split\n",
    "op_test = df.loc[test_mask, \"PROGNOSE_REIZEN\"].astype(float)\n",
    "op_mae  = mean_absolute_error(y_test, op_test)\n",
    "op_rmse = np.sqrt(mean_squared_error(y_test, op_test))\n",
    "op_r2   = r2_score(y_test, op_test)\n",
    "\n",
    "print(\"\\nOperator Forecast (PROGNOSE_REIZEN) — Test results:\")\n",
    "print(f\"MAE: {op_mae:.2f}\")\n",
    "print(f\"RMSE: {op_rmse:.2f}\")\n",
    "print(f\"R²: {op_r2:.3f}\")\n",
    "\n",
    "# --- 7) Compare multiple feature subsets (aligned with trees-style features) ---\n",
    "feature_sets = {\n",
    "    \"Set 1: Base + Delay cats\": base_features + [\"delay_category\"],\n",
    "    \"Set 2: Base + Disruption cats\": base_features + [\"disruption_category\"],\n",
    "    \"Set 3: Base + Weather\": base_features + weather_features,\n",
    "    \"Set 4: Base + Disruptions full\": base_features + disrupt_features,\n",
    "    \"Set 5: Base + Delay and Disruption cats\": base_features + [\"delay_category\", \"disruption_category\"],\n",
    "    \"Set 6: ALL\": features_all,  # \n",
    "    \n",
    "}\n",
    "\n",
    "# === Build comparison table (incl. disrupted metrics) & save the best overall-MAE model ===\n",
    "\n",
    "# Consistent one-hot categories\n",
    "FORCE_CAT = {\"DAGDEELTREIN\", \"train_type\", \"delay_category\", \"disruption_category\"}\n",
    "\n",
    "# Disrupted mask (OR rule)\n",
    "NO_DELAY_LABEL = \"no delay (0-1 min)\"\n",
    "NO_DISR_LABEL  = \"no disruption\"\n",
    "def disrupted_mask(idx):\n",
    "    dcat = df.loc[idx, \"delay_category\"].astype(str).str.strip().str.lower() if \"delay_category\" in df.columns else \"nan\"\n",
    "    disc = df.loc[idx, \"disruption_category\"].astype(str).str.strip().str.lower() if \"disruption_category\" in df.columns else \"nan\"\n",
    "    return (dcat != NO_DELAY_LABEL) | (disc != NO_DISR_LABEL)\n",
    "\n",
    "test_idx = df.index[test_mask]\n",
    "dis_mask_test = disrupted_mask(test_idx).values\n",
    "\n",
    "results = []\n",
    "best_overall = {\"mae\": np.inf, \"name\": None, \"model\": None, \"cols\": None}\n",
    "\n",
    "for name, feat_list in feature_sets.items():\n",
    "    # keep only existing cols\n",
    "    feat_list = [c for c in feat_list if c in df.columns]\n",
    "    X_sub = df[feat_list].copy()\n",
    "\n",
    "    # one-hot: union of forced cats + auto object/string cols\n",
    "    auto_cat = [c for c in feat_list if X_sub[c].dtype == \"object\" or pd.api.types.is_string_dtype(X_sub[c])]\n",
    "    cat_cols = sorted(set(auto_cat) | (set(feat_list) & FORCE_CAT))\n",
    "    X_sub = pd.get_dummies(X_sub, columns=cat_cols, drop_first=True)\n",
    "\n",
    "    # split\n",
    "    X_tr = X_sub[train_mask]\n",
    "    y_tr = y[train_mask]\n",
    "    X_te = X_sub[test_mask]\n",
    "    y_te = y[test_mask]\n",
    "\n",
    "    # fit plain Linear for fair comparison\n",
    "    m = LinearRegression()\n",
    "    m.fit(X_tr, y_tr)\n",
    "    y_hat = m.predict(X_te)\n",
    "\n",
    "    # overall metrics\n",
    "    mae  = mean_absolute_error(y_te, y_hat)\n",
    "    rmse = np.sqrt(mean_squared_error(y_te, y_hat))\n",
    "    r2   = r2_score(y_te, y_hat)\n",
    "\n",
    "    # disrupted-only metrics\n",
    "    if dis_mask_test.any():\n",
    "        mae_d  = mean_absolute_error(y_te[dis_mask_test], y_hat[dis_mask_test])\n",
    "        rmse_d = np.sqrt(mean_squared_error(y_te[dis_mask_test], y_hat[dis_mask_test]))\n",
    "        r2_d   = r2_score(y_te[dis_mask_test], y_hat[dis_mask_test])\n",
    "    else:\n",
    "        mae_d = rmse_d = r2_d = np.nan\n",
    "\n",
    "    results.append({\n",
    "        \"Feature Set\": name,\n",
    "        \"MAE (Model)\": round(mae, 2),\n",
    "        \"RMSE (Model)\": round(rmse, 2),\n",
    "        \"R² (Model)\": round(r2, 3),\n",
    "        \"MAE (Disrupted)\": round(mae_d, 2),\n",
    "        \"RMSE (Disrupted)\": round(rmse_d, 2),\n",
    "        \"R² (Disrupted)\": round(r2_d, 3),\n",
    "        \"n_features\": X_tr.shape[1]\n",
    "    })\n",
    "\n",
    "    # keep best by overall MAE\n",
    "    if mae < best_overall[\"mae\"]:\n",
    "        best_overall = {\"mae\": mae, \"name\": name, \"model\": m, \"cols\": X_sub.columns.tolist()}\n",
    "\n",
    "# Operator baseline row (overall + disrupted)\n",
    "op_test = df.loc[test_mask, \"PROGNOSE_REIZEN\"].astype(float).values\n",
    "y_test_all = y_test.values\n",
    "op_mae  = round(mean_absolute_error(y_test_all, op_test), 2)\n",
    "op_rmse = round(np.sqrt(mean_squared_error(y_test_all, op_test)), 2)\n",
    "op_r2   = round(r2_score(y_test_all, op_test), 3)\n",
    "\n",
    "if dis_mask_test.any():\n",
    "    op_mae_d  = round(mean_absolute_error(y_test_all[dis_mask_test], op_test[dis_mask_test]), 2)\n",
    "    op_rmse_d = round(np.sqrt(mean_squared_error(y_test_all[dis_mask_test], op_test[dis_mask_test])), 2)\n",
    "    op_r2_d   = round(r2_score(y_test_all[dis_mask_test], op_test[dis_mask_test]), 3)\n",
    "else:\n",
    "    op_mae_d = op_rmse_d = op_r2_d = np.nan\n",
    "\n",
    "operator_row = {\n",
    "    \"Feature Set\": \"Operator Forecast (baseline)\",\n",
    "    \"MAE (Model)\": op_mae,\n",
    "    \"RMSE (Model)\": op_rmse,\n",
    "    \"R² (Model)\": op_r2,\n",
    "    \"MAE (Disrupted)\": op_mae_d,\n",
    "    \"RMSE (Disrupted)\": op_rmse_d,\n",
    "    \"R² (Disrupted)\": op_r2_d,\n",
    "    \"n_features\": 1\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame([operator_row] + results).sort_values(by=\"MAE (Model)\").reset_index(drop=True)\n",
    "\n",
    "# pretty print table\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.expand_frame_repr\", False)\n",
    "pd.set_option(\"display.width\", 220)\n",
    "print(\"\\n=== Comparison of feature sets (Linear Regression) ===\")\n",
    "print(results_df)\n",
    "\n",
    "# Save THE model & context for later cells\n",
    "THE_FEATURE_SET_NAME = best_overall[\"name\"]\n",
    "THE_FEATURE_COLUMNS  = best_overall[\"cols\"]      # post-one-hot columns\n",
    "THE_MODEL_PIPE       = best_overall[\"model\"]     # already fit on train split columns above\n",
    "\n",
    "print(f\"\\nSaved THE model: {THE_FEATURE_SET_NAME}  | Overall Test MAE={best_overall['mae']:.2f}  | n_features={len(THE_FEATURE_COLUMNS)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035e76dd",
   "metadata": {},
   "source": [
    "### Tuning the LR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "23748793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear                     | VAL MAE (all): 64.038\n",
      "Ridge(0.1)                 | VAL MAE (all): 64.037\n",
      "Ridge(1.0)                 | VAL MAE (all): 64.037\n",
      "Ridge(3.0)                 | VAL MAE (all): 64.036\n",
      "Ridge(10.0)                | VAL MAE (all): 64.032\n",
      "Ridge(30.0)                | VAL MAE (all): 64.022\n",
      "Ridge(100.0)               | VAL MAE (all): 63.987\n",
      "Lasso(0.0001)              | VAL MAE (all): 64.038\n",
      "Lasso(0.001)               | VAL MAE (all): 64.037\n",
      "Lasso(0.01)                | VAL MAE (all): 64.035\n",
      "Lasso(0.1)                 | VAL MAE (all): 64.012\n",
      "Lasso(0.5)                 | VAL MAE (all): 63.948\n",
      "Lasso(1.0)                 | VAL MAE (all): 63.912\n",
      "ElasticNet(a=0.001,l1=0.2) | VAL MAE (all): 64.012\n",
      "ElasticNet(a=0.001,l1=0.5) | VAL MAE (all): 64.021\n",
      "ElasticNet(a=0.001,l1=0.8) | VAL MAE (all): 64.031\n",
      "ElasticNet(a=0.01,l1=0.2)  | VAL MAE (all): 63.807\n",
      "ElasticNet(a=0.01,l1=0.5)  | VAL MAE (all): 63.885\n",
      "ElasticNet(a=0.01,l1=0.8)  | VAL MAE (all): 63.972\n",
      "ElasticNet(a=0.1,l1=0.2)   | VAL MAE (all): 63.587\n",
      "ElasticNet(a=0.1,l1=0.5)   | VAL MAE (all): 63.393\n",
      "ElasticNet(a=0.1,l1=0.8)   | VAL MAE (all): 63.572\n",
      "ElasticNet(a=0.5,l1=0.2)   | VAL MAE (all): 72.025\n",
      "ElasticNet(a=0.5,l1=0.5)   | VAL MAE (all): 67.435\n",
      "ElasticNet(a=0.5,l1=0.8)   | VAL MAE (all): 63.858\n",
      "\n",
      "Best tuned: ElasticNet(a=0.1,l1=0.5) | VAL MAE=63.393\n",
      "Best tuned — TEST (all):  MAE=60.01 RMSE=91.26 R²=0.820\n",
      "THE model — TEST (all):   MAE=59.21 RMSE=91.04 R²=0.821\n",
      "\n",
      "Selected model for further steps: Untuned Linear (Set 4: Base + Disruptions full)\n"
     ]
    }
   ],
   "source": [
    "# Tune THE model's feature set (fix: rebuild from raw features, reapply one-hot, align columns)\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# --- 1) Rebuild X from the RAW features of THE_FEATURE_SET_NAME, re-encode exactly like in Cell 1 ---\n",
    "raw_feat_list = feature_sets[THE_FEATURE_SET_NAME]                   # raw columns (pre one-hot)\n",
    "raw_feat_list = [c for c in raw_feat_list if c in df.columns]        # keep existing\n",
    "\n",
    "X_raw = df[raw_feat_list].copy()\n",
    "\n",
    "FORCE_CAT = {\"DAGDEELTREIN\",\"train_type\",\"delay_category\",\"disruption_category\"}\n",
    "auto_cat = [c for c in raw_feat_list if X_raw[c].dtype == \"object\" or pd.api.types.is_string_dtype(X_raw[c])]\n",
    "cat_cols = sorted(set(auto_cat) | (set(raw_feat_list) & FORCE_CAT))\n",
    "\n",
    "X_enc = pd.get_dummies(X_raw, columns=cat_cols, drop_first=True)\n",
    "\n",
    "# Align to the exact columns the saved model was trained on (order + presence)\n",
    "X_enc = X_enc.reindex(columns=THE_FEATURE_COLUMNS, fill_value=0.0)\n",
    "\n",
    "# --- 2) Chronological split + internal validation days (same logic as before) ---\n",
    "cutoff_day = df[\"DAGNR\"].max() - 7\n",
    "train_mask = df[\"DAGNR\"] <= cutoff_day\n",
    "test_mask  = df[\"DAGNR\"] >  cutoff_day\n",
    "\n",
    "train_days = np.sort(df.loc[train_mask, \"DAGNR\"].unique())\n",
    "val_days_count = max(1, int(0.2 * len(train_days)))\n",
    "val_days = set(train_days[-val_days_count:])\n",
    "tr_days  = set(train_days[:-val_days_count]) if val_days_count < len(train_days) else set()\n",
    "if len(tr_days) == 0:\n",
    "    val_days = set(train_days[-2:])\n",
    "    tr_days  = set(train_days[:-2])\n",
    "\n",
    "train_sub_mask = train_mask & df[\"DAGNR\"].isin(tr_days)\n",
    "valid_mask     = train_mask & df[\"DAGNR\"].isin(val_days)\n",
    "\n",
    "X_tr, y_tr = X_enc[train_sub_mask], df.loc[train_sub_mask, \"REALISATIE\"].astype(float)\n",
    "X_va, y_va = X_enc[valid_mask],     df.loc[valid_mask, \"REALISATIE\"].astype(float)\n",
    "X_te, y_te = X_enc[test_mask],      df.loc[test_mask,  \"REALISATIE\"].astype(float)\n",
    "\n",
    "# --- 3) Disrupted masks (optional reporting) ---\n",
    "NO_DELAY_LABEL = \"no delay (0-1 min)\"\n",
    "NO_DISR_LABEL  = \"no disruption\"\n",
    "def disrupted_mask(idx):\n",
    "    dcat = df.loc[idx, \"delay_category\"].astype(str).str.strip().str.lower() if \"delay_category\" in df.columns else \"nan\"\n",
    "    disc = df.loc[idx, \"disruption_category\"].astype(str).str.strip().str.lower() if \"disruption_category\" in df.columns else \"nan\"\n",
    "    return (dcat != NO_DELAY_LABEL) | (disc != NO_DISR_LABEL)\n",
    "\n",
    "va_dis = disrupted_mask(df.index[valid_mask]).values\n",
    "te_dis = disrupted_mask(df.index[test_mask]).values\n",
    "\n",
    "# --- 4) Candidates (linear + regularized) ---\n",
    "cands = []\n",
    "cands.append((\"Linear\", Pipeline([(\"scaler\", StandardScaler(with_mean=False)), (\"model\", LinearRegression())])))\n",
    "for a in [0.1, 1.0, 3.0, 10.0, 30.0, 100.0]:\n",
    "    cands.append((f\"Ridge({a})\", Pipeline([(\"scaler\", StandardScaler(with_mean=False)), (\"model\", Ridge(alpha=a, random_state=42))])))\n",
    "for a in [1e-4, 1e-3, 1e-2, 1e-1, 0.5, 1.0]:\n",
    "    cands.append((f\"Lasso({a})\", Pipeline([(\"scaler\", StandardScaler(with_mean=False)), (\"model\", Lasso(alpha=a, max_iter=20000, random_state=42))])))\n",
    "for a in [1e-3, 1e-2, 1e-1, 0.5]:\n",
    "    for l1 in [0.2, 0.5, 0.8]:\n",
    "        cands.append((f\"ElasticNet(a={a},l1={l1})\",\n",
    "                      Pipeline([(\"scaler\", StandardScaler(with_mean=False)),\n",
    "                                (\"model\", ElasticNet(alpha=a, l1_ratio=l1, max_iter=20000, random_state=42))])))\n",
    "\n",
    "# --- 5) Optimize for overall MAE on validation ---\n",
    "best_label, best_pipe, best_val = None, None, np.inf\n",
    "for label, pipe in cands:\n",
    "    pipe.fit(X_tr, y_tr)\n",
    "    y_hat_va = pipe.predict(X_va)\n",
    "    mae_va = mean_absolute_error(y_va, y_hat_va)\n",
    "    print(f\"{label:<26} | VAL MAE (all): {mae_va:.3f}\")\n",
    "    if mae_va < best_val:\n",
    "        best_val, best_pipe, best_label = mae_va, pipe, label\n",
    "\n",
    "# --- 6) Evaluate tuned vs THE (untuned) on TEST with correct aligned design matrix ---\n",
    "y_hat_te_tuned = best_pipe.predict(X_te)\n",
    "mae_te  = mean_absolute_error(y_te, y_hat_te_tuned)\n",
    "rmse_te = np.sqrt(mean_squared_error(y_te, y_hat_te_tuned))\n",
    "r2_te   = r2_score(y_te, y_hat_te_tuned)\n",
    "\n",
    "print(f\"\\nBest tuned: {best_label} | VAL MAE={best_val:.3f}\")\n",
    "print(\"Best tuned — TEST (all):  MAE={:.2f} RMSE={:.2f} R²={:.3f}\".format(mae_te, rmse_te, r2_te))\n",
    "\n",
    "# THE_MODEL_PIPE was trained in Cell 1 on the same column set. Use identical X_enc columns here:\n",
    "y_hat_te_the = THE_MODEL_PIPE.predict(X_enc[test_mask])  # SAME X_enc design matrix / columns\n",
    "mae_the  = mean_absolute_error(y_te, y_hat_te_the)\n",
    "rmse_the = np.sqrt(mean_squared_error(y_te, y_hat_te_the))\n",
    "r2_the   = r2_score(y_te, y_hat_te_the)\n",
    "print(\"THE model — TEST (all):   MAE={:.2f} RMSE={:.2f} R²={:.3f}\".format(mae_the, rmse_the, r2_the))\n",
    "\n",
    "# --- 7) Choose model to carry forward ---\n",
    "if mae_te <= mae_the:\n",
    "    SELECTED_MODEL_NAME = f\"Tuned {best_label}\"\n",
    "    SELECTED_PIPE = best_pipe\n",
    "else:\n",
    "    SELECTED_MODEL_NAME = f\"Untuned Linear ({THE_FEATURE_SET_NAME})\"\n",
    "    SELECTED_PIPE = THE_MODEL_PIPE\n",
    "\n",
    "print(f\"\\nSelected model for further steps: {SELECTED_MODEL_NAME}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b238981",
   "metadata": {},
   "source": [
    "### Best fitting model's coefficient importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d52ab70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Top 15 Standardized Coefficients — Set 4: Base + Disruption flags and cats ===\n",
      "                           Feature  Standardized_Coefficient   AbsValue\n",
      "                   PROGNOSE_REIZEN                203.272979 203.272979\n",
      "              DAGDEELTREIN_Daluren                -18.429856  18.429856\n",
      "              DAGDEELTREIN_Weekend                -18.006919  18.006919\n",
      "           Previous train canceled                 17.039733  17.039733\n",
      "              DAGDEELTREIN_Unknown                 12.810525  12.810525\n",
      "                        ExtraTrain                 12.810525  12.810525\n",
      "         DAGDEELTREIN_Ochtendspits                -11.300351  11.300351\n",
      "    delay_category_Small (1-5 min)                  9.353866   9.353866\n",
      "  delay_category_Medium (5-10 min)                  8.069645   8.069645\n",
      " disruption_category_No Disruption                  6.688127   6.688127\n",
      "               train_type_Sprinter                  3.673553   3.673553\n",
      "                    train_type_TGV                  3.660088   3.660088\n",
      "                       disrupt_any                  3.028461   3.028461\n",
      "delay_category_Very Large (+30min)                 -2.286565   2.286565\n",
      "            Previous train delayed                 -1.861947   1.861947\n"
     ]
    }
   ],
   "source": [
    "# --- Standardized coefficients for BEST feature set model ---\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "best_name = \"Set 4: Base + Disruption flags and cats\"\n",
    "best_features = feature_sets[best_name]\n",
    "best_features = [c for c in best_features if c in df.columns]\n",
    "X_best = df[best_features].copy()\n",
    "\n",
    "# one-hot encode categoricals\n",
    "cat_cols_best = [c for c in best_features if X_best[c].dtype == \"object\" or pd.api.types.is_string_dtype(X_best[c])]\n",
    "X_best = pd.get_dummies(X_best, columns=cat_cols_best, drop_first=True)\n",
    "\n",
    "# use only training split\n",
    "X_train_best = X_best[train_mask]\n",
    "y_train_best = y[train_mask]\n",
    "\n",
    "# standardize and fit linear model\n",
    "scaler = StandardScaler()\n",
    "X_scaled_best = scaler.fit_transform(X_train_best)\n",
    "model_std = LinearRegression()\n",
    "model_std.fit(X_scaled_best, y_train_best)\n",
    "\n",
    "# collect coefficients\n",
    "std_coefs = pd.DataFrame({\n",
    "    \"Feature\": X_train_best.columns,\n",
    "    \"Standardized_Coefficient\": model_std.coef_,\n",
    "    \"AbsValue\": np.abs(model_std.coef_)\n",
    "}).sort_values(\"AbsValue\", ascending=False)\n",
    "\n",
    "print(f\"\\n=== Top 15 Standardized Coefficients — {best_name} ===\")\n",
    "print(std_coefs.head(15).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bae20b",
   "metadata": {},
   "source": [
    "## MLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6ab8555d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MLP — Test: MAE=57.09 RMSE=88.71 R²=0.830\n",
      "Untuned Linear (Set 4: Base + Disruptions full) — Test: MAE=59.21 RMSE=91.04 R²=0.821\n",
      "Winner: MLP (lower MAE)\n",
      "\n",
      "Disrupted runs in TEST (OR rule): 7767 / 23459\n",
      "\n",
      "MLP — Disrupted runs:\n",
      "MAE=66.39 RMSE=103.07 R²=0.806\n",
      "Untuned Linear (Set 4: Base + Disruptions full) — Disrupted runs:\n",
      "MAE=67.84 RMSE=104.50 R²=0.801\n",
      "Operator — Disrupted runs:\n",
      "MAE=71.26 RMSE=113.18 R²=0.766\n"
     ]
    }
   ],
   "source": [
    "# MLP on the same feature set\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# --- 1) Rebuild from RAW features of THE_FEATURE_SET_NAME, re-encode, then align to THE_FEATURE_COLUMNS ---\n",
    "raw_feat_list = feature_sets[THE_FEATURE_SET_NAME]\n",
    "raw_feat_list = [c for c in raw_feat_list if c in df.columns]\n",
    "X_raw = df[raw_feat_list].copy()\n",
    "\n",
    "FORCE_CAT = {\"DAGDEELTREIN\",\"train_type\",\"delay_category\",\"disruption_category\"}\n",
    "auto_cat = [c for c in raw_feat_list if X_raw[c].dtype == \"object\" or pd.api.types.is_string_dtype(X_raw[c])]\n",
    "cat_cols = sorted(set(auto_cat) | (set(raw_feat_list) & FORCE_CAT))\n",
    "\n",
    "X_enc = pd.get_dummies(X_raw, columns=cat_cols, drop_first=True)\n",
    "# align exactly to the post-one-hot training columns used by THE model\n",
    "X_enc = X_enc.reindex(columns=THE_FEATURE_COLUMNS, fill_value=0.0)\n",
    "\n",
    "# --- 2) Chronological split + internal validation inside train ---\n",
    "cutoff_day = df[\"DAGNR\"].max() - 7\n",
    "train_mask = df[\"DAGNR\"] <= cutoff_day\n",
    "test_mask  = df[\"DAGNR\"] >  cutoff_day\n",
    "\n",
    "train_days = np.sort(df.loc[train_mask, \"DAGNR\"].unique())\n",
    "val_days_count = max(1, int(0.2 * len(train_days)))\n",
    "val_days = set(train_days[-val_days_count:])\n",
    "tr_days  = set(train_days[:-val_days_count]) if val_days_count < len(train_days) else set()\n",
    "if len(tr_days) == 0:\n",
    "    val_days = set(train_days[-2:])\n",
    "    tr_days  = set(train_days[:-2])\n",
    "\n",
    "train_sub_mask = train_mask & df[\"DAGNR\"].isin(tr_days)\n",
    "valid_mask     = train_mask & df[\"DAGNR\"].isin(val_days)\n",
    "\n",
    "X_tr = X_enc[train_sub_mask].values.astype(\"float32\")\n",
    "y_tr = df.loc[train_sub_mask, \"REALISATIE\"].astype(float).values.astype(\"float32\")\n",
    "X_va = X_enc[valid_mask].values.astype(\"float32\")\n",
    "y_va = df.loc[valid_mask, \"REALISATIE\"].astype(float).values.astype(\"float32\")\n",
    "X_te = X_enc[test_mask].values.astype(\"float32\")\n",
    "y_te = df.loc[test_mask,  \"REALISATIE\"].astype(float).values.astype(\"float32\")\n",
    "\n",
    "# --- 3) Scale (safe with one-hots) ---\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "X_tr = scaler.fit_transform(X_tr)\n",
    "X_va = scaler.transform(X_va)\n",
    "X_te = scaler.transform(X_te)\n",
    "\n",
    "# --- 4) MLP ---\n",
    "tf.keras.backend.clear_session()\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Input(shape=(X_tr.shape[1],)),\n",
    "    keras.layers.Dense(256, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(optimizer=keras.optimizers.Adam(1e-3), loss=\"mae\")\n",
    "es = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True, monitor=\"val_loss\", verbose=0)\n",
    "\n",
    "model.fit(X_tr, y_tr, validation_data=(X_va, y_va),\n",
    "          epochs=200, batch_size=1024, callbacks=[es], verbose=0)\n",
    "\n",
    "# --- 5) Evaluate MLP vs the selected classical model on the EXACT same X_enc ---\n",
    "y_pred_nn = model.predict(X_te, verbose=0).ravel()\n",
    "mae_nn  = mean_absolute_error(y_te, y_pred_nn)\n",
    "rmse_nn = np.sqrt(mean_squared_error(y_te, y_pred_nn))\n",
    "r2_nn   = r2_score(y_te, y_pred_nn)\n",
    "\n",
    "y_hat_sel = SELECTED_PIPE.predict(X_enc[test_mask])  # uses same aligned matrix\n",
    "mae_sel  = mean_absolute_error(y_te, y_hat_sel)\n",
    "rmse_sel = np.sqrt(mean_squared_error(y_te, y_hat_sel))\n",
    "r2_sel   = r2_score(y_te, y_hat_sel)\n",
    "\n",
    "print(f\"\\nMLP — Test: MAE={mae_nn:.2f} RMSE={rmse_nn:.2f} R²={r2_nn:.3f}\")\n",
    "print(f\"{SELECTED_MODEL_NAME} — Test: MAE={mae_sel:.2f} RMSE={rmse_sel:.2f} R²={r2_sel:.3f}\")\n",
    "\n",
    "print(\"Winner:\", \"MLP (lower MAE)\" if mae_nn < mae_sel else \"Selected linear model (lower MAE)\")\n",
    "\n",
    "# --- Disrupted-only metrics (delay != 'No delay (0-1 min)' OR disruption != 'No Disruption') ---\n",
    "\n",
    "NO_DELAY_LABEL = \"no delay (0-1 min)\"\n",
    "NO_DISR_LABEL  = \"no disruption\"\n",
    "\n",
    "def disrupted_mask(idx):\n",
    "    dcat = df.loc[idx, \"delay_category\"].astype(str).str.strip().str.lower() if \"delay_category\" in df.columns else \"nan\"\n",
    "    disc = df.loc[idx, \"disruption_category\"].astype(str).str.strip().str.lower() if \"disruption_category\" in df.columns else \"nan\"\n",
    "    return (dcat != NO_DELAY_LABEL) | (disc != NO_DISR_LABEL)\n",
    "\n",
    "test_idx = df.index[test_mask]\n",
    "dis_mask_test = disrupted_mask(test_idx).values\n",
    "n_dis = int(dis_mask_test.sum())\n",
    "print(f\"\\nDisrupted runs in TEST (OR rule): {n_dis} / {len(dis_mask_test)}\")\n",
    "\n",
    "if n_dis > 0:\n",
    "    # MLP on disrupted\n",
    "    mae_nn_d  = mean_absolute_error(y_te[dis_mask_test], y_pred_nn[dis_mask_test])\n",
    "    rmse_nn_d = np.sqrt(mean_squared_error(y_te[dis_mask_test], y_pred_nn[dis_mask_test]))\n",
    "    r2_nn_d   = r2_score(y_te[dis_mask_test], y_pred_nn[dis_mask_test])\n",
    "\n",
    "    # Selected linear on disrupted (uses same aligned X_enc)\n",
    "    y_hat_sel_d = y_hat_sel[dis_mask_test]\n",
    "    mae_sel_d  = mean_absolute_error(y_te[dis_mask_test], y_hat_sel_d)\n",
    "    rmse_sel_d = np.sqrt(mean_squared_error(y_te[dis_mask_test], y_hat_sel_d))\n",
    "    r2_sel_d   = r2_score(y_te[dis_mask_test], y_hat_sel_d)\n",
    "\n",
    "    # Operator baseline on disrupted (optional)\n",
    "    op_test = df.loc[test_mask, \"PROGNOSE_REIZEN\"].astype(float).values\n",
    "    op_test_d = op_test[dis_mask_test]\n",
    "    mae_op_d  = mean_absolute_error(y_te[dis_mask_test], op_test_d)\n",
    "    rmse_op_d = np.sqrt(mean_squared_error(y_te[dis_mask_test], op_test_d))\n",
    "    r2_op_d   = r2_score(y_te[dis_mask_test], op_test_d)\n",
    "\n",
    "    print(\"\\nMLP — Disrupted runs:\")\n",
    "    print(f\"MAE={mae_nn_d:.2f} RMSE={rmse_nn_d:.2f} R²={r2_nn_d:.3f}\")\n",
    "\n",
    "    print(f\"{SELECTED_MODEL_NAME} — Disrupted runs:\")\n",
    "    print(f\"MAE={mae_sel_d:.2f} RMSE={rmse_sel_d:.2f} R²={r2_sel_d:.3f}\")\n",
    "\n",
    "    print(\"Operator — Disrupted runs:\")\n",
    "    print(f\"MAE={mae_op_d:.2f} RMSE={rmse_op_d:.2f} R²={r2_op_d:.3f}\")\n",
    "else:\n",
    "    print(\"No disrupted runs found in test set.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Geospatial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
